# zhihu-contents
A collection of my own Zhihu articles，⭐ means I am very satisfied with this article

## Attention Based Model
### 1. Vision Transformer
- ⭐[【T2T-ViT】Tokens-to-Token ViT: Training Vision Transformers from Scratch on Imagenet 学习笔记](https://zhuanlan.zhihu.com/p/359930253)
- ⭐ [DynamicViT：动态Token稀疏化ViT](https://zhuanlan.zhihu.com/p/380353779)

### 2. Efficient Attention
- ⭐ [Reformer: The Efficient Transformer 解析](https://zhuanlan.zhihu.com/p/360074457)
- [ISSA：通过long-range short-range交互降低Attention计算复杂度](https://zhuanlan.zhihu.com/p/363355768)
- ⭐[【Dynamic Conv】Pay Less Attention With Lightweight And Dynamic Convolutions 解析](https://zhuanlan.zhihu.com/p/364163868)

### 3. Attention Module in CNN
- [Rotate to Attend: Convolutional Triplet Attention Module 学习笔记](https://zhuanlan.zhihu.com/p/360028132)
